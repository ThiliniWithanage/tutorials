# Copyright 2019 Wirepas Ltd

# fluentd/conf/fluent.conf
<source>
  @type forward
  port 24224
  bind 0.0.0.0
  @log_level info
</source>

<system>
  workers 8
</system>

<filter rtt.**>
  @type parser
  format json
  key_name log # field to parse
  reserve_data true
</filter>


<filter **>
  @type elasticsearch_genid
  hash_id_key _hash    # storing generated hash id key (default is _hash)
</filter>

# omit other source / match
<match fluent.*>
  @type stdout
</match>

# transform the rtt time key into rxtime
<filter rtt.**>
  @type record_transformer
  enable_ruby
  <record>
    rxtime ${record["time"]}
  </record>
</filter>

<match **.**>
    @type elasticsearch

    type_name _doc
    host elasticsearch
    port 9200

    flatten_hashes true
    flatten_hashes_separator _

    write_operation create
    id_key _hash # specify same key name which is specified in hash_id_key
    remove_keys _hash # Elasticsearch doesn't like keys that start with _

    logstash_format true
    logstash_prefix ${tag}
    logstash_dateformat %Y%m%d

    include_tag_key true
    time_key rxtime
    time_precision 9
    time_key_format %Y-%m-%dT%H:%M:%S.%NZ
    include_timestamp true

    reconnect_on_error true
    reload_on_failure true
    reload_connections true
    reload_after 10000

    type_name wm_log
    tag_key @log_name

    <buffer>
      @type memory
      retry_wait 1                      # The wait interval for the first retry.
      retry_exponential_backoff_base 2  # Increase the wait time by a factor of N.
      retry_type exponential_backoff    # Set 'periodic' for constant intervals.
      retry_randomize true              # Apply randomization. (see above)
      retry_max_times 10                # Maximum retry count before giving up.
      retry_forever false               # Set 'true' for infinite retry loops.
      flush_thread_count 4
    </buffer>                           # 'Output Plugins' > 'Overview'.

    @log_level error

</match>
